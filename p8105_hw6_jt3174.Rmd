---
title: "p8105_hw6_jt3174"
author: "Jingyi Tang"
date: "11/23/2019"
output: github_document
---

```{r set up}

# ensure reproductivity
set.seed(1)

# load library
library(tidyverse)
library(modelr)
library(mgcv)
library(ggplot2)
library(viridis)
library(ggridges)

knitr::opts_chunk$set(
  # display the code in the code truck above its results in the final document
  echo = TRUE,
  # do not display any warning messages generated by the code
  warning = FALSE,
  # set the figure to be 8 x 6, and the proportion it takes to be 90%
  fig.width = 8,
  fig.height = 6, 
  out.width = "90%"
)

# setting a global options for continuous data color family and a different format to set discrete data to have a color family
options(
  ggplot2.countinuous.colour = "viridis",
  ggplot2.countinuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# have a minimal theme and legends at the bottom
theme_set(theme_minimal() + theme(legend.position = "bottom"))

```


## Problem 1

```{r load and clean data}

# Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

baby = read_csv("./data/birthweight.csv") %>% 
  # clean names
  janitor::clean_names() %>% 
  # use case_when to give the values of certain variables new values
  mutate(
    # baby’s sex (male = 1, female = 2)
    babysex = as.factor(case_when(
      babysex == 1 ~ "male",
      babysex == 2 ~ "female"
    )),
    # father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown)
    frace = as.factor(case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown"
    )),
    # presence of malformations that could affect weight (0 = absent, 1 = present)
    malform = as.factor(case_when(
      malform == 0 ~ "absent",
      malform == 1 ~ "present"
    )),
    # mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
    mrace = as.factor(case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
    ))  
  )

# checking if there is any missing value in the fataframe called baby
# if all of the values in the table returned were 0's, there are no missing values
sapply(baby, function(x) sum(is.na(x))) %>% 
  knitr::kable(., col.names = "Number of Missing Value", caption = "Table for Variables and Their Missing Values")

```

There is no missing value in the dataset `baby`, and this dataset is cleaned as stated in the homework page.

For a regression model to propose, I decided to use anova to test nested model. I started with full regression, and then decided by the p-value of each factor in the model to decide to keep or not for the proposed model. And then I will use anova test these two models to decided the final proposed model in this step. 

```{r regression models}

# full regression model
full_model = lm(bwt ~ ., data = baby)

# diaplay the model summary
summary(full_model)$coefficient%>%
  knitr::kable(., col.names = c("Estimate", "Std. Error", "t value","Pr(>|t|)"), caption = "result of main effect linear regression model")

```

Here, accoding to the p-values, I am going to keep the varaibles `babysex`, `bhead`, `blength`, `delwt`, `gaweeks`, `parity`, `smoke`. 

```{r regression model proposed}

# proposed model with 
proposed_model = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + parity + smoken, data = baby)

# diaplay the model summary
summary(proposed_model)$coefficient%>%
  knitr::kable(., col.names = c("Estimate", "Std. Error", "t value","Pr(>|t|)"), caption = "result of main effect linear regression model")

# use anova() to decide which model is better
anova(proposed_model, full_model) %>% 
  broom::tidy()

```

We can see that the proposed model is a nested model for full model, and accoding to the F-test, p-value = 1.03464e-56 < significance level at 0.05, the proposed model is better than the full model. 

```{r regression model}
# add residual and prediction to the orginal dataframe
baby_residual_prediction = baby %>% 
  add_predictions(proposed_model) %>% 
  add_residuals(proposed_model)

# create residual vs fitted plot
baby_residual_prediction %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .5, color = "darksalmon") +
  labs(title = "Residuals vs. Fitted Value Plot for Proposed Model",
       x = "Fitted Values",
       y = "Residuals",
       caption = "Data provided by Jeff") +
  geom_hline(aes(yintercept = 0), color = "darkgrey") 

```

We can see that residual vs. fitted plot did not indicated that the proposed model is a good regression model since the scatterplot is not random.

Here, we fit two regression models stated in the homework page. 

```{r regression models to be compared for birthweight}

# One using length at birth and gestational age as predictors (main effects only)

main_effect_model = lm(bwt ~ blength + gaweeks, data = baby)

# diaplay the model summary
summary(main_effect_model)$coefficient%>%
  knitr::kable(., col.names = c("Estimate", "Std. Error", "t value","Pr(>|t|)"), caption = "result of main effect linear regression model")

# One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

interaction_model = lm(bwt ~ bhead * blength * babysex , data = baby)

# display the model summary
summary(interaction_model)$coefficient%>%
  knitr::kable(., col.names = c("Estimate", "Std. Error", "t value","Pr(>|t|)"), caption = "result of interaction linear regression model")

```

```{r cross-validated prediction error}

# Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

# crossv_mc preforms the training / testing split multiple times, a stores the datasets using list columns.
cv_df = crossv_mc(baby, 100)

cv_df = cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = cv_df %>% 
  # create models
  mutate(proposed_model  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + parity + smoken, data = .x)),
         main_effect_model  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         interaction_model  = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  # calculate rmse
  mutate(rmse_proposed = map2_dbl(proposed_model, test, ~rmse(model = .x, data = .y)),
         rmse_main_effect = map2_dbl(main_effect_model, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(interaction_model, test, ~rmse(model = .x, data = .y)))

```

I will make a violin plot to show the distribution of rmse for these three models to find the relatively best fit for this data.

```{r}

cv_df %>% 
  # select only variable started with rmse
  select(starts_with("rmse")) %>% 
  # convert into long form
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  # relevel the factor by first appearance
  mutate(model = fct_inorder(model)) %>% 
  # plot: x-axis - model; y-axis = rmse; fill difference colors by model
  ggplot(aes(x = model, y = rmse, fill = model)) +
  # violin plot
  geom_violin(alpha = 0.5) +
  labs(title = "Violin Plot of RMSE in Different Models",
       x = "Models",
       y = "Root Mean of Square Error",
       caption = "Data provided by Jeff") +
  theme(plot.title = element_text(hjust = 0.5))

```

Based on these results, there's clearly improvements between the main effect model and interaction and proposed model. The proposed model is slightly better than interaction model, although the evidence is not by much, the advance is not obvious. Hence, here I would use the proposed model.

## Problem 2

```{r load data}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

```{r bootstrap}

# draw bootstrap samples
boot_straps = weather_df %>% 
  modelr::bootstrap(n = 5000)

# repeat analysis pipeline using the bootstrap function 
boot_straps = boot_straps %>% 
         # models contain info of regression model of each term in strap
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)),
         # results contains tidied data of the regression model
         results = map(models, broom::tidy),
         variables = map(models, broom::glance)) %>% 
  # get rid of strap and models, but keep everything else
  select(-strap, -models) %>% 
  # expand the data
  unnest(results, variables)

```

```{r r-hat squared 95% CI}

r_square_CI = boot_straps %>% 
  # keep only the value that has value "tmin"
  filter(term == "tmin") %>% 
  pull(., r.squared) %>% 
  # obtain CI
  quantile(., c(.025, .975)) %>% 
  # convert to dataframe
  as.data.frame()

```

The CI of $\hat{r}^2$ that comes from bootstrap is (`r pull(r_square_CI, .)[1] `, `r pull(r_square_CI, .)[2]`).

```{r r-hat squared plot}

boot_straps %>% 
  # keep only tmin-related info
  filter(term == "tmin") %>% 
  # plot: x-axis = r-squared
  ggplot(aes(x = r.squared)) +
  # density plot
  geom_density(alpha = 0.5, fill = "darksalmon") +
  # add first quartile line
  geom_vline(aes(xintercept = pull(r_square_CI, .)[1]), color = "darkgreen", linetype = "longdash") +
  # add thrid quartile line
  geom_vline(aes(xintercept = pull(r_square_CI, .)[2]), color = "darkorange", linetype = "longdash") +
  labs(
    title = "Density Plot of the Estimate of R square",
    x = "Estimate of R square",
    y = "Density",
    caption = "Data here comes from 2017 Central Park Weather Data")

```

According to density of $\hat{r}^2$, we can see that this is close to normal curve. We can also tell from the CI that most of data were distributed around the center. Hence, we can say that the estimate $\hat{r}^2$ is roughly distributed normally.

```{r log(beta0*beta1)}

log_estimates = boot_straps %>% 
  # keep only variables: term, estimate
  select(term, estimate) %>% 
  # convert to wide form to get beta0(aka. intercept) and beta1(tmin)
  pivot_wider(
    # get term value to be new variable names
    names_from = term,
    # get estimate value to be new values according to their term
    values_from = estimate
  ) %>% 
  # clean names
  janitor::clean_names(.) %>% 
  # expand the intercept and t$min
  unnest(intercept, tmin) %>% 
  # add a variable to indicate log(beta0*beta1)
  mutate(log_betas = log(intercept * tmin))

log_estimates_CI = log_estimates %>% 
  pull(., log_betas) %>% 
  # obtain CI
  quantile(., c(.025, .975)) %>% 
  # convert to dataframe
  as.data.frame()

```

The CI of $log(\hat{β}_0*\hat{β}_1)$ that comes from bootstrap is (`r pull(log_estimates_CI, .)[1]`, `r pull(log_estimates_CI, .)[2]`).

```{r log estimate density plot}

log_estimates %>% 
  # x-axis: log_betas
  ggplot(aes(x = log_betas)) +
  # density plot
  geom_density(fill = "darksalmon", alpha = 0.5) +
  # add first quartile line
  geom_vline(aes(xintercept = pull(log_estimates_CI, .)[1]), color = "darkgreen", linetype = "longdash") +
  # add thrid quartile line
  geom_vline(aes(xintercept = pull(log_estimates_CI, .)[2]), color = "darkorange", linetype = "longdash") +
  labs(
    title = "Density Plot of Natural Log of the Product of Estimate Beta's",
    x = "Natural Log of Estimate Betas' Product",
    y = "Density",
    caption = "Data here comes from 2017 Central Park Weather Data")


```

According to density of $log(\hat{β}_0*\hat{β}_1)$, we can see that this is close to normal curve. We can also tell from the CI that most of data were distributed around the center. Hence, we can say that the estimate $log(\hat{β}_0*\hat{β}_1)$ is roughly distributed normally. This density plot is not as "normal"/"belled" as $\hat{r}^2$'s distribution.